# Task-2

Step 1: Data Collection
I collected a dataset with detailed information about Spotify tracks. The dataset included fields like genre, artist name, track name, popularity, acousticness, energy, danceability, valence, loudness, tempo, and time signature.

Step 2: Data Cleaning and Preparation
I used Power Query in Power BI to clean the dataset by:

Removing null and duplicate rows

Changing incorrect data types

Replacing errors and renaming columns for clarity

Step 3: Visual Creation
I created several visuals to explore the data:

Stacked Column Chart showing average popularity by genre

Stacked Bar Chart showing time signature by acousticness level and track ID

Gauge Chart displaying average valence with a target score of 0.7 to represent cheerful songs

Step 4: Card Visuals (Key Summary Metrics)
I added card visuals to show quick insights:

Unique Artists: Count of different artists in the dataset

Unique Tracks: Total number of songs

Total Genres: Number of distinct music genres

Musical Modes: Count of modes (major or minor scale)

Step 5: Interactive Slicer
To make the dashboard user-friendly, I added a slicer for:

Loudness: Lets users filter songs based on how loud or soft they are. This helps in analyzing whether a song is calm, energetic, or somewhere in between.

Step 6: Target and KPI
To analyze the emotional mood of the songs, I used a gauge chart:

Average Valence: Shows how positive or happy the songs are on average

Target Value: Set at 0.7 to represent a happy or upbeat tone
This helps users quickly understand whether the dataset contains mostly happy or sad music.


 



